{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-27T19:35:37.871757Z","iopub.execute_input":"2021-11-27T19:35:37.872289Z","iopub.status.idle":"2021-11-27T19:35:37.890098Z","shell.execute_reply.started":"2021-11-27T19:35:37.872258Z","shell.execute_reply":"2021-11-27T19:35:37.889224Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/nlpprojinput/train.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nnltk.download('stopwords')\nnltk.download('punkt')\nnltk.download('averaged_perceptron_tagger')\nnltk.download('wordnet')\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.metrics import f1_score, accuracy_score\nfrom wordcloud import WordCloud, STOPWORDS\nfrom collections import Counter, defaultdict\nimport random\nimport time\nimport datetime\nimport torch\nfrom transformers import BertTokenizer, BertForSequenceClassification, AdamW, BertConfig, get_linear_schedule_with_warmup\nfrom torch.utils.data import TensorDataset, random_split, DataLoader, RandomSampler, SequentialSampler\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:35:37.891707Z","iopub.execute_input":"2021-11-27T19:35:37.892090Z","iopub.status.idle":"2021-11-27T19:35:44.830956Z","shell.execute_reply.started":"2021-11-27T19:35:37.892052Z","shell.execute_reply":"2021-11-27T19:35:44.830210Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('../input/nlpprojinput/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:35:44.832434Z","iopub.execute_input":"2021-11-27T19:35:44.832658Z","iopub.status.idle":"2021-11-27T19:35:47.078753Z","shell.execute_reply.started":"2021-11-27T19:35:44.832626Z","shell.execute_reply":"2021-11-27T19:35:47.077977Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:35:47.080099Z","iopub.execute_input":"2021-11-27T19:35:47.080353Z","iopub.status.idle":"2021-11-27T19:35:48.430632Z","shell.execute_reply.started":"2021-11-27T19:35:47.080318Z","shell.execute_reply":"2021-11-27T19:35:48.429954Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e41c6ebb00344ec080c2a951bdde881a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2af7c4a2c6a04ebf9bf89da0219ba319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6a94da6d34744afb924a3723a1a4635"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_map(sentence,labels):       \n    input_ids = []\n    attention_masks = []\n    \n    for text in sentence:\n        encoded_dict = tokenizer.encode_plus(\n                            text,                      \n                            add_special_tokens = True, \n                            truncation='longest_first', \n                            max_length = 84,           \n                            pad_to_max_length = True, \n                            return_attention_mask = True,  \n                            return_tensors = 'pt')\n        input_ids.append(encoded_dict['input_ids'])        \n        attention_masks.append(encoded_dict['attention_mask'])\n            \n    input_ids = torch.cat(input_ids, dim=0)\n    attention_masks = torch.cat(attention_masks, dim=0) \n    labels = torch.tensor(labels)\n    return input_ids, attention_masks, labels","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:35:48.432296Z","iopub.execute_input":"2021-11-27T19:35:48.432617Z","iopub.status.idle":"2021-11-27T19:35:48.439908Z","shell.execute_reply.started":"2021-11-27T19:35:48.432579Z","shell.execute_reply":"2021-11-27T19:35:48.439223Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"labels = df['label'].values\ndf = df.fillna(' ') \ntext = df['text'].values\nprint(text.shape)\ninput_ids, attention_masks, labels = tokenize_map(text, labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:36:02.780685Z","iopub.execute_input":"2021-11-27T19:36:02.780959Z","iopub.status.idle":"2021-11-27T19:45:50.680548Z","shell.execute_reply.started":"2021-11-27T19:36:02.780909Z","shell.execute_reply":"2021-11-27T19:45:50.679768Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"(20800,)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  FutureWarning,\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = TensorDataset(input_ids, attention_masks, labels)\ntrain_dataset, val_dataset = train_test_split(dataset, test_size=0.20)\nprint(len(train_dataset),'training samples', len(val_dataset),  'validation samples')","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:45:50.682113Z","iopub.execute_input":"2021-11-27T19:45:50.682367Z","iopub.status.idle":"2021-11-27T19:45:50.995678Z","shell.execute_reply.started":"2021-11-27T19:45:50.682332Z","shell.execute_reply":"2021-11-27T19:45:50.994074Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"16640 training samples 4160 validation samples\n","output_type":"stream"}]},{"cell_type":"code","source":"batch_size = 15\n\ntrain_dataloader = DataLoader(\n            train_dataset,  \n            sampler = RandomSampler(train_dataset), \n            batch_size = batch_size)\n\nvalidation_dataloader = DataLoader(\n            val_dataset, \n            sampler = SequentialSampler(val_dataset), \n            batch_size = batch_size )","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:45:50.997224Z","iopub.execute_input":"2021-11-27T19:45:50.997514Z","iopub.status.idle":"2021-11-27T19:45:51.002152Z","shell.execute_reply.started":"2021-11-27T19:45:50.997477Z","shell.execute_reply":"2021-11-27T19:45:51.001463Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\nmodel = BertForSequenceClassification.from_pretrained(\n    'bert-large-uncased',\n    num_labels = 2, \n    output_attentions = False, \n    output_hidden_states = False,\n)\nmodel.to(device)\noptimizer = AdamW(model.parameters(),lr = 6e-6,eps = 1e-8 )","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:45:51.003779Z","iopub.execute_input":"2021-11-27T19:45:51.004480Z","iopub.status.idle":"2021-11-27T19:48:03.052679Z","shell.execute_reply.started":"2021-11-27T19:45:51.004438Z","shell.execute_reply":"2021-11-27T19:48:03.051962Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"cuda:0\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf6de342379a4f2eac3ea05ebc8d54a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.34G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e531c2753b74abb8d89f7c228d2d8e2"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"epochs = 3\ntotal_steps = len(train_dataloader) * epochs\nscheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0,num_training_steps = total_steps)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:48:25.951514Z","iopub.execute_input":"2021-11-27T19:48:25.952059Z","iopub.status.idle":"2021-11-27T19:48:25.957017Z","shell.execute_reply.started":"2021-11-27T19:48:25.952021Z","shell.execute_reply":"2021-11-27T19:48:25.955897Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def calc_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return accuracy_score(labels_flat, pred_flat)","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:48:28.566723Z","iopub.execute_input":"2021-11-27T19:48:28.567388Z","iopub.status.idle":"2021-11-27T19:48:28.576960Z","shell.execute_reply.started":"2021-11-27T19:48:28.567332Z","shell.execute_reply":"2021-11-27T19:48:28.575662Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\ntraining_stats = []\nfor epoch_i in range(epochs):\n\n    print('Epoch {} / {} '.format(epoch_i + 1, epochs))\n    print('Training')\n    \n    total_train_loss = 0\n    model.train()\n    for step, batch in enumerate(train_dataloader):   \n        if step % 100 == 0:\n            print(\"Step completed:\", step)\n        \n        b_input_ids = batch[0].to(device).to(torch.int64)\n        b_input_mask = batch[1].to(device).to(torch.int64)\n        b_labels = batch[2].to(device).to(torch.int64)\n        \n        model.zero_grad()        \n        loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask,labels=b_labels)[0]\n        logits = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)[1]\n        total_train_loss += loss.item()\n        \n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        optimizer.step()\n        scheduler.step()\n    \n    avg_train_loss = total_train_loss / len(train_dataloader)            \n    print('Average training loss:', avg_train_loss)\n    \n    #validation\n    print('Validation')\n    model.eval()\n    total_eval_accuracy = 0\n    total_eval_loss = 0\n    total_eval_f1 = 0\n    nb_eval_steps = 0\n    \n    for batch in validation_dataloader:\n        b_input_ids = batch[0].to(device)\n        b_input_mask = batch[1].to(device)\n        b_labels = batch[2].to(device)\n                \n        with torch.no_grad():        \n            loss = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)[0]\n\n            logits = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)[1]\n        \n        total_eval_loss += loss.item() \n        logits = logits.detach().cpu().numpy()\n        label_ids = b_labels.to('cpu').numpy()\n        total_eval_accuracy += calc_accuracy(logits, label_ids)\n            \n    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n    print('Accuracy', avg_val_accuracy)    \n    avg_val_loss = total_eval_loss / len(validation_dataloader)\n    print('Loss:', avg_val_loss)\n    \n    training_stats.append({'epoch': epoch_i + 1,'train_loss': avg_train_loss,'val_loss': avg_val_loss,'val_acc.': avg_val_accuracy})\nprint(\"DONE\")","metadata":{"execution":{"iopub.status.busy":"2021-11-27T19:48:32.341279Z","iopub.execute_input":"2021-11-27T19:48:32.341539Z","iopub.status.idle":"2021-11-27T20:24:26.346727Z","shell.execute_reply.started":"2021-11-27T19:48:32.341510Z","shell.execute_reply":"2021-11-27T20:24:26.345952Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Epoch 1 / 3 \nTraining\nStep completed: 0\nStep completed: 100\nStep completed: 200\nStep completed: 300\nStep completed: 400\nStep completed: 500\nStep completed: 600\nStep completed: 700\nStep completed: 800\nStep completed: 900\nStep completed: 1000\nStep completed: 1100\nAverage training loss: 0.1390891531834469\nValidation\nAccuracy 0.9784172661870512\nLoss: 0.10225286170421084\nEpoch 2 / 3 \nTraining\nStep completed: 0\nStep completed: 100\nStep completed: 200\nStep completed: 300\nStep completed: 400\nStep completed: 500\nStep completed: 600\nStep completed: 700\nStep completed: 800\nStep completed: 900\nStep completed: 1000\nStep completed: 1100\nAverage training loss: 0.03466083063148953\nValidation\nAccuracy 0.982973621103118\nLoss: 0.09205385164573959\nEpoch 3 / 3 \nTraining\nStep completed: 0\nStep completed: 100\nStep completed: 200\nStep completed: 300\nStep completed: 400\nStep completed: 500\nStep completed: 600\nStep completed: 700\nStep completed: 800\nStep completed: 900\nStep completed: 1000\nStep completed: 1100\nAverage training loss: 0.010482721607384208\nValidation\nAccuracy 0.9848920863309357\nLoss: 0.09388610958160452\nDONE\n","output_type":"stream"}]},{"cell_type":"code","source":"# calculating metrics\n\nfrom sklearn.metrics import precision_score, recall_score\ndef calc_f1(preds, labels):    \n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return f1_score(labels_flat, pred_flat)\n\ndef calc_precision(preds, labels):    \n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return precision_score(labels_flat, pred_flat)\n\ndef calc_recall(preds, labels):    \n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return precision_score(labels_flat, pred_flat) \n\nmodel.eval()\naccuracy_sum = 0\ntotal_eval_loss = 0\nf1_sum = 0\nprecision_sum = 0\nrecall_sum = 0\nnb_eval_steps = 0\n    \nfor batch in validation_dataloader:\n    b_input_ids = batch[0].to(device)\n    b_input_mask = batch[1].to(device)\n    b_labels = batch[2].to(device)\n\n    with torch.no_grad():        \n        loss = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)[0]\n\n        logits = model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)[1]\n\n    total_eval_loss += loss.item() \n    logits = logits.detach().cpu().numpy()\n    label_ids = b_labels.to('cpu').numpy()\n    \n    accuracy_sum += calc_accuracy(logits, label_ids)\n    f1_sum += calc_f1(logits, label_ids)\n    precision_sum += calc_precision(logits, label_ids)\n    recall_sum += calc_recall(logits, label_ids)\n\n\nprint('Accuracy',accuracy_sum / len(validation_dataloader))\nprint('Precision', precision_sum / len(validation_dataloader))\nprint('Recall', recall_sum / len(validation_dataloader))\nprint('F1', f1_sum / len(validation_dataloader))\nprint('Loss:', total_eval_loss / len(validation_dataloader))","metadata":{"execution":{"iopub.status.busy":"2021-11-27T20:27:00.992206Z","iopub.execute_input":"2021-11-27T20:27:00.992483Z","iopub.status.idle":"2021-11-27T20:28:13.839896Z","shell.execute_reply.started":"2021-11-27T20:27:00.992455Z","shell.execute_reply":"2021-11-27T20:28:13.839180Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Accuracy 0.9848920863309357\nPrecision 0.9913967527276881\nRecall 0.9913967527276881\nF1 0.9833987518233149\nLoss: 0.09388610958160452\n","output_type":"stream"}]}]}